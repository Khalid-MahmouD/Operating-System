presence of interrupts on a single process(or multiple thread excuting on multiple processors concurently).
locks, programmers annote ðŸ” source code with locks, putting them around critical sections, 
thus ensure that any such critical section excutes as if it were a single atomic instruction.


28.1 Locks: The Basic Idea

updata of a shared variable:
balance = balance + 1;

Of course, other critical sections are possible, such as adding an element to a linked list or other more complex updates to shared structures,

To use a lock, we add some code around the critical section like this:
lock_t mutex; // some globally-allocated lock â€™mutexâ€™
...
lock(&mutex);
balance = balance + 1;
unlock(&mutex);

a lock is just a variable, and to use one, you must declare a lock variable(e.g..mutex above).
lock holds tha state of the lock at any instant in time, 1ï¸âƒ£ available,(unlocked or free) no thread holds the lock,
or 2ï¸âƒ£ acquired (locked or held), and thus exactly one thread hold the lock and is in a critical section.

we could store other info. in data type as well, 
1ï¸âƒ£  which thread hold the lock, a queue for ordering lock acquisition, 
2ï¸âƒ£  all is hidden from the user of the lock.

The semantics of the lock() and unlock() routines are simple.
calling lock() routine tries to acquire the lock; if no other thread hold the lock(i.e it is free), thread will acquire the lock,
entring the critical section; thread this called the owner of the lock.

if another thread then call lock() with same variable mutex, it will not return while the lock is held by another thread;
â­•in this way, other threads are prevented from entering the critical section while the first thread that holds the lock is in there. 

once the owner calls unlock() the lock is available again.
1ï¸âƒ£ no other thread waiting for the lock, state of the lock simply changed to free.(no thread has called lock() an stuck waiting).
2ï¸âƒ£ if there are waiting threads (stuck in lock()), one of them will (eventually)  notice (or be informed of) this change of lock's state,       acqurire the lock, enter critical section.


Locks provide some minimal amount of control over scheduling to programmers.
threads created by programmer but scheduled by the OS, in any fashion OS choose.
Locks yield some of that control back to the programmer;
the programmer can guarantee that no more than a single thread can ever be active within that code.
Thus locks help transform the chaos that is traditional OS scheduling into a more controlled activity.
Ø§Ù„Ø«Ø±Ø¯Ø² Ø§Ù„Ø¨Ø±ÙˆØ¬Ø±Ø§Ù…Ø± Ù‡Ùˆ Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ¹Ù…Ù„Ù‡Ø§ Ø¨Ø³ Ø¨ÙŠØªÙ… ØªØ±ØªØ¨Ù‡Ø§ Ø­Ø³Ø¨ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„
Ø§Ù„Ø§Ù‚ÙØ§Ù„ Ø¨ØªØ¶ÙŠÙ‚ ÙÙŠØªØ´ÙŠØ±Ø² Ø§Ù† Ø§Ù„Ø¨Ø±ÙˆØ¬Ø±Ø§Ù…Ø± Ù‡Ùˆ Ø§Ù„Ù„ÙŠ Ù‡ÙŠØ¹Ù…Ù„Ù‡Ø§ ÙˆÙŠÙ†Ø¸Ù…Ù‡Ø§ ÙƒÙ…Ø§Ù† Ø¨Ø­ÙŠØ« Ù…ÙÙŠØ´ ØºÙŠØ± Ø«Ø±ÙŠØ¯ ÙˆØ§Ø­Ø¯Ø© Ù‡ÙŠ Ø§Ù„Ù„ÙŠ ØªØ´ØªØºÙ„
ÙˆØ¨Ø¯Ù„ Ø§Ù„ÙÙˆØ¶ÙŠ Ø¨ØªØ§Ø¹ Ø§Ù„Ø§Ø³ÙƒÙŠØ¯ÙˆØ§Ù„Ø± Ø¨ØªØ§Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ù‡ÙŠØ¨Ù‚ÙŠ Ø§ÙƒØªØ± ØªØ­ÙƒÙ… Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø¨Ø±ÙˆØ¬Ø±Ø§Ù…Ø±

28.2 Pthread Locks

the name POSIX library uses for lock is a mutux, used to provide mutual exclusion between threads,
i.e., any thread in critical section, it exclude the others from entering until it has completed the section.
(we use our wrappers  that check for errors upon lock and unlock):

  pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
  Pthread_mutex_lock(&lock); // wrapper for pthread_mutex_lock()
  balance = balance + 1;
  Pthread_mutex_unlock(&lock);

we can use different locks to protect different variables, increaing concurrency:
1ï¸âƒ£ instead of one big lock that is used any time any  critical section is accessed
(a coarse-grained locking strategy),the whole package is ðŸ”’ .

2ï¸âƒ£ one will often protect different data and data structures with different locks, thus allowing more threads to be in locked code at once
(a more fine-grained approach).


28.3 Building A Lock
by now you know how lock works, but how should we build a lock?
what hardware support is needed? what OS support? how we cam build efficient lock? provide mutex at low cost?

a number of different hardware primitives have been added to the instruction sets of various computer architectures;
we don't study how implement, but we study how to use them in order to build a mutual exclusion primitive like lock.
we need to study how OS gets involved to complete the picture and enable us to build a sophisticated locking library.


28.4 Evaluating Locks
befor building any locks, we should first understand what  our goals are, and ask how to evaluate the efficacy of particular 
lock implementation.

wheather the lock deos the basic task, 
which is provide ((mutual exclusion)), does the lock work ((preventing multiple threads from entering a critical section ))?

fairness,does each thread contending for the lock get a fair shot at acquiring it once it is free?
	does any thread contending for the lock starve while doing so, thus never obtaining it?

performance, time overheads added by using lock.
no contention; single thead is running grabs and releases the lock, what overhead of doing so?
multiple threads are contending for the lock on a single CPU;
muliple CPUs involved, and threads on each contending for the lock? 
we can better understand the performance impact of using various locking techniques, as described below.


28.5 Controlling Interrupts

solution earliest solutions used to provide mutual exclusion was disable interrupts for critical sections; 
for single-processor systems.
code:
void lock() {
   DisableInterrupts();
}
void unlock() {
   EnableInterrupts();
}

by turning off interrupts (using some kind of special hardware instruction) before entering a critical section, 
we ensure that code inside critical section will not be interrupted, and will excuted as if it were atomic.(grab lock)
when we finished, we re-enable interrupts (again via a hardware instruction), and thus the program proceeds as usual.(release lock)

positive of this approach is its simplicity.
with no interrupts, a thead ensure that the code it excuted will excute and no other thread will interface with it.

The negatives, unfortunately, are many
1. requires us to allow any calling thread to perform a privileged operation (turning interrupts on and off) and thus trust that  this    facility is not abused.
 . any time we are required to trust an arbitrary program, we are probably in trouble,
   gready program could call lock() at the beginning of its excution, thus monopolize the processor;
   worse, errant or malicious program could call lock() and go into endless loop.
 . OS never gain control again, restart system as solution.
   Using interrupt disabling, requires toomuch trust in applications.

2. the approach does not work on multiprocessors.
   If multiple threads are running on different CPUs, and each try to enter the same critical section, 
   it does not matter whether interrupts are disabled; threads will be able to run on other processors, and thus
   could enter critical section.

3. this aproach can be inefficient.
   masks or unmasks interrupts tends to be excuted slowly by modern CPUs.

for these reasons, turning off interrupts is only used in limited context as mutual exclusion primitive.
for example, OS use interrupt masking to guarantee atomicity when accessing its own data structures, 
or prevent certain messy interrupt handling situation from arising.
OS trust it self to perform privilaged operations anyhow. 

ASIDE: DEKKERâ€™S AND PETERSONâ€™S ALGORITHMS
Unlike the solutions we discuss here, which use special hardware instructions and even OS support	
Dekkerâ€™s approach uses just loads and stores (assuming they are atomic with respect to each other, which was true on early hardware).

just loads and stores are used, and the idea is to ensure that two threads never enter a critical section at the same time.
int flag[2];
int turn;
void init() {
	flag[0] = flag[1] = 0; // 1->thread wants to grab lock
	turn = 0; // whose turn? (thread 0 or 1?)
}
void lock() {
	flag[self] = 1; // self: thread ID of caller
	turn = 1 - self; // make it other threadâ€™s turn
	while ((flag[1 - self] == 1) && (turn == 1 - self))
		; // spin-wait
}
void unlock() {
	flag[self] = 0; // simply undo your intent
}


28.6 Test And Set (Atomic Exchange)
disabling interrupts does not work with multiple processors, start to invent hardware support for locking.
		typedef struct __lock_t { int flag; } lock_t;

		void init(lock_t * mutex) {
		 	// 0 -> lock is available, 1 -> held
	 		mutex->flag = 0;
	
		}

		 void lock(lock_t* mutex) {
	 		while (mutex->flag == 1) // TEST the flag
		 		; // spin-wait (do nothing)
	 		mutex->flag = 1; // now SET it!

		 }

 		void unlock(lock_t* mutex) {
			 mutex->flag = 0
 		}
;---------------------------------------------------------------First Attempt: A Simple Flag

the simplest bit of hardware support to understand is what is known as a test-and-set instruction, atomic exchange.
we use simple flag variable to donate whether the lock is held or not.

in first attempt, idea quite simple: use a simple variable to indicate whether some thread has possession of a lock().

senario 1:
the first thread enters the critical section will call lock(), which tests whether the flag is equal to 1 ?(it is not, in this case),
and sets the flag to 1 to indicate that the thread now holds the lock.

finished with critical section the thread calls unlock() and clears the flag, that indicating tha lock no longer held.

senario 2:
another thread 	happens to call lock(), while that first thread in critical section, it simply spin-wait in while loop until the thread
call unlock() and clear the flag. once the first thread done so, waiting one will set the flag after get out of while loop,
and proceed into critical section.


two problems
1- correctness
2- performance
1ï¸âƒ£  correctness problem is simple to see once you get used to thinking about concurrent programming (assuming flag = 0 to begin)

		thread 1				thread2
		---------------------------------------------------
		call lock()
		while(flag == 1)
		interrupt: switch to thread 2
							call lock()
							while(flag == 1)
							flag = 1; //take it for it self!!
							interrupt: switch to thread 1
		flag = 1 //take it too!
;--------------------------------------Table 28.1: Trace: No Mutual Exclusion


where both threads set their flags to 1 and both threads are thus able to enter the critical section. This is bad! We
have obviously failed to provide the most basic requirement: providing mutual exclusion.

2ï¸âƒ£ the performance problem, thread waits to acquire a lock that is already held: checking the value of flag, technique known as spin-   	waiting. and that  technique wastes timewaiting for another thread to release a lock.

3ï¸âƒ£ on uniporcessor, the wast is high, where the thread that the waiter is waiting for can not even run, so moving forward and develop more 
sophisticated solution,we should also consider ways to avoid this kind of waste.


28.7 Building A Working Spin Lock
it is not possible to implement without some support from the hardware.
some systems provide an instruction to support the creation of simple locks based on this concept.
more powerful instruction  it is the load/store unsigned byte instruction (ldstub), whereas on x86,

xchg instruction but basically does the same thing across platforms, referred to as test-and-set.


return old valure pointed by ptr, and update said value to new. the sequance of operation is performed atomically.
call test-and-set enables  you to test the old value, and setting the memory location to new value.

more powerful instruction is enough to build a simple spin lock, as we now examine in Figure 28.2

int TestAndSet(int* ptr, int new) {
	 int old = *ptr; // fetch old value at ptr
	 * ptr = new; // store â€™newâ€™ into ptr
	 return old; // return the old value
	
}
typedef struct __lock_t {
	 int flag;
	
} lock_t;

void init(lock_t * lock) {
	 // 0 indicates that lock is available, 1 that it is held
		 lock->flag = 0;
		
}

void lock(lock_t * lock) {
	while (TestAndSet(&lock->flag, 1) == 1)
		;// spin-wait (do nothing)
	
}

 void unlock(lock_t * lock) {
	 lock->flag = 0;
}
;----------------------------------------------------Figure 28.2: A Simple Spin Lock Using Test-and-set
Letâ€™s make sure we understand why this works
1st case:
1. the case where a thread calls lock() and no other thread currently holds the lock; flag should be 0.
   when thread calls TestAndSet(flag, 1), the routine return old flag which is 0; calling thread that (testing) the flag value,
   will not get caught spinning in the while loop and will acquire the lock.
   thread atomically set the value to 1, indicating that the lock is now held.
   finishing with critical section call unlock() to clear the flag = 0;

2nd case:
2. the lock held(i.e., flag is 1). thread in this case, this thread will call TestAndSet(flag, 1)as well.
   and returning the old value with is 1 (cause the lock is held). while simultaneously setting it to 1 again. 
   As long as the lock is held by another thread, TestAndSet() will repeatedly return 1, and thus this
   thread will spin and spin until the lock is finally released. When the flag is finally set to 0 by some other thread, this thread will      call TestAndSet() again, which will now return 0 while atomically setting the value to 1 and thus acquire the lock and enter the       critical section.

By making both the test (of the old lock value) and set (of the new value) a single atomic operation, we ensure that only one thread acquires the lock. how to build a working mutual exclusion primitive!

this type of locks usually referred to as a spin lock. simplest type of lock to build, and
simply spins, using CPU cycles, until the lock becomes available.
To work correctly on a single processor, it requires a preemptive scheduler (i.e., one that will interrupt a thread via a timer, in order to run a different thread, from time to time).

Without preemption, spin locks donâ€™t make much sense on a single CPU, as a thread spinning on a CPU will never relinquish it.


28.8 Evaluating Spin Locks

given basic spin lock, we can now evaluate how effective it is along our previously described axes.

the most important aspect of a lock is correctness: does it provide mutual exclusion ? the answe here is yes:
the spin lock only one thread allowed to enter the critical section at a time.

the next axis is fairness. How fair is a spin lock to a waiting thread? 
can we make sure that the waiting thread will ever enter the critical section?
bad news : spin locks don't provide any fairness guarantees. thread spinningmay spin forever, under contention. Ù…Ù…ÙƒÙ† ØªÙØ¶Ù„ ØªÙ„Ù ÙˆÙ‡ÙŠ Ù„Ø³Ù‡ Ø¨ØªØªØ´Ùƒ Ø¹Ù„ÙŠ Ø§Ù„ÙÙ„Ø§Ø¬ ÙˆØªØ·Ø§Ù„Ø¨ Ø¨Ø¯Ø®ÙˆÙ„Ù‡Ø§
Spin locks are not fair and may lead to starvation.

The final axis is performance. What are the costs of using a spin lock?
To analyze this more carefully, we suggest thinking about a few different cases.

threads competing for the lock on a signle processor;
threads spread out across many processors.

in single CPU case, performance overhead can be quite painful;
imagin a thread pre-empted within a critical section and held the lock.
the scheduler run every other thread, each of which try to acquire the lock. 
in this case, each will spin for the duration of a time slice before giving up the cpu, a wast of CPU cycles. 


multiple CPUs, spin locks work reasonably well (if the number of threads roughly equals the number of CPUs).
thread A on CPU 1 and thread B on CPU 2, both conteding for a lock. if A grabs the lock, if B tries to, it will spin on CPU 2.
it probably critical section is short, soon lock become available, and acquired by B.
spinning to wait for a lock held on another processor dosn't waste many cycles in this case, and thus can be quite effective.

28.9 Compare-And-Swap

Another hardware primitive that some systems provide is known as the compare-and-swap instruction or compare-and-exchange.
The basic idea is for compare-and-swap to test whether the value at the  address specified by ptr is equal to expected; 
if so, update the memory location pointed to by ptr with the new value. If not, do nothing.

in either case, return the actual value at that memory location, 
thus allowing the code calling compare-and-swap to know whether it succeeded or not.

we can build a lock in a manner quite similar to that with test-and-set.

int CompareAndSwap(int* ptr, int expected, int new) {
	int actual = *ptr;
	if (actual == expected)
		*ptr = new;
	return actual;
}
void lock(lock_t* lock) {
	while (CompareAndSwap(&lock->flag, 0, 1) == 1)
		;// spin
}

This code works quite similarly it simply checks if the flag is 0 and if so, atomically swaps in a 1 thus acquiring the lock.
Threads that try to acquire the lock while it is held will get stuck spinning until the lock is finally released.

Finally, as you may have sensed, compare-and-swap is a more powerful instruction than test-and-set.

why? test-and-set modifies the contents of a memory location and returns its old value as a single atomic operation.

compare-and-swap atomically compares the contents of a memory location to a given value and, only if they are the same, modifies the contents of that memory location to a given new value.

28.10 Load-Linked and Store-Conditional
some platforms provide a pair of instruction that work concert to help build critical section.
for example, the load-linked and store-conditional instructions can be used in tandem ÙˆØ§Ø­Ø¯ ÙˆØ§Ø­Ø¯ to build locks and other concurrent structures.

int LoadLinked(int* ptr) {
	 return *ptr;
	
}
int StoreConditional(int* ptr, int value) {
	if (no one has updated * ptr since the LoadLinked to this address) {
		*ptr = value;
		return 1; // success!

	}
	else {
		return 0; // failed to update

	}

}
/*LESS CODE IS BETTER CODE*/
// short-circuiting boolean conditionals.
//void lock(lock_t* lock) {
//	 while (LoadLinked(&lock->flag) || !StoreConditional(&lock->flag, 1))
//		; // spin
//}
void lock(lock_t* lock) {
	while (1) {
		while (LoadLinked(&lock->flag) == 1)
			; // spin until itâ€™s zero
		if (StoreConditional(&lock->flag, 1) == 1)
			return; // if set-it-to-1 was a success: all done
		// otherwise: try it all over again

	}

}

 void unlock(lock_t * lock) {
	 lock->flag = 0;
	
}
;---------------------------Using LL/SC To Build A Lock
;-------------------------------------------------------Figure 28.4: Load-linked And Store-conditional-----------------

load-linked operator much like load instruction, simply fetches a value from memory and place it in a register.
key difference come with store-conditional, which only succeeds if no intermittent store to the address has taken place.
in the case of success, store-conditional returns 1 and update value of ptr to value;
in the case of fails, the value ptr in not updated and 0 is returned.

howto build a lock using load-linked and store-conditional.above after modifying,
lock() part, thread spinning waiting to the flag get 0,(the lock in not held).
thus trying acquiring the lock via the store-conditional; if it succeeds, flag set to 1 and thus can proceed into critical section.

Note how failure of the store-conditional might arise!!.
thread call lock() excute load-linked, returning 0 as the lock is not held.
before it can attempt the store-conditional, 
          interrupted and another thread enters the lock code, executing the load-linked instruction, returning also 0 and continuing,
#two threads have each executed the load-linked and each are about to attempt the store-conditional.

ðŸ”¥The key feature of these instructions is that only one of these threads will succeed in updating the flag to 1 and thus acquire the lock;

the second thread to attempt the store-conditional will fail (because the other thread updated the value of flag between its load-linked and storeconditional) and thus have to try to acquire the lock again.



28.11 Fetch-And-Add