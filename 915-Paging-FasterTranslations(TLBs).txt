chopping address space into small, fixed-sized units,pages, paging requires a large amount of mapping information.
genarly stored in physical memory, paging requiers an extra memory lookup for each virtual address generated by the programe.
Going to memory for translation information before every instruction fetch or explicit load or store is prohibitively slow.

how we can speed address translation? and avoid extra memory ? what hardware support is required? what OS involvement is needed?

When we want to make things fast, the OS usually needs some help, from the hardware. 
To speed address translation, we are going to add what is called  (for historical reasons [CP78]) 
a translation-lookaside buffer, or TLB [C68, C95]. 

A TLB is part of the chip‚Äôs memory-management unit (MMU), ((hardware cache of popular virtual-to-physical address translations)); 
thus, a better name would be an address-translation cache. 

Upon each I)((virtual memory reference)), II) the hardware first checks the TLB to see if the desired
translation is held therein; if so, III)the translation is performed (quickly)
without having to IV)consult the page table (which has all translations). 

Because of their tremendous performance impact, TLBs in a real sense make virtual memory possible [C95].

19.1 TLB Basic Algorithm
hardware  might handle a virtual address translation
assuming a simple linear page table (Array), and hardware-managed TLB 
hardware  handles mush of accessing page-table.

//---------------------------------------------Code-Algorithms------------------------
//initially 
   VPN = (VirtualAddress & VPN_MASK)>>SHIFT
  (Success, TlbEntry) = TLB_Lookup(VPN)
//----TLB----
if (Success == True) // TLB Hit
 if (CanAccess(TlbEntry.ProtectBits) == True) //proctection test not faild
 Offset = VirtualAddress & OFFSET_MASK
 PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
 AccessMemory(PhysAddr)
 else
 RaiseException(PROTECTION_FAULT)

//----Page-table-entry-address----
else // TLB Miss
 PTEAddr = PTBR + (VPN * sizeof(PTE))          //base-register pointer 
 PTE = AccessMemory(PTEAddr)        
 if (PTE.Valid == False)                       //
 RaiseException(SEGMENTATION_FAULT)
 else if (CanAccess(PTE.ProtectBits) == False) //could be accessible !!
 RaiseException(PROTECTION_FAULT)
 else
 TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
 RetryInstruction()
//-----------------------------------------------endOf-Code----------------------------

VA: offset, VPN    
        ---------------------------------------------------------------------
	|   VA5    |  VA4     |   VA3    |   VA2      |   VA1      |  VA0   |
        ---------------------------------------------------------------------
        ^                     ^                                             ^
	|        VPN          |                  OFFSET                     |
VPN_MASK == 110000(0X03);
SHIFT == set to 4(number of bits in offset

I) extract virtual page number from Virtual address(VPN), and Chech if TLB holds the translation for this VPN.

II) if it does we have a TLB hit, and it means TLB holds the translation, now we can extract 
    page frame number(PFN) and concatenate that onto offset from original vitrual address,
    and have desire Physical Address, and accessing memory, 
    assuming protection checks do not fail

III)if CPU doesn't find translation in the TLB (a TLB miss), we do some more work,
    
    I)accessing page table and find the translation,update TLB with the translation.
      assuming that the virtual memory reference generated by the process is valid and accessible.

    II)update TLB with the translation, these coslty cause we use extra memory reference needs to access page table
    
    III)the hardware retries the instruction; this time, the translation is found in the TLB, 
        and the memory reference is processed quickly.


relative to most CPU instructions, are quite costly, and TLB misses lead to more memory accesses. Thus, it is our hope to avoid TLB misses as much as we can.



19.2 Example: Accessing An Array 

            offset
       0    04   08   12    16 
       ----------------------
VPN 00 |    |     |    |    |
       ----------------------
VPN 01 |    |     |    |    |
       ----------------------
VPN 02 |    |     |    |    |
       ----------------------
VPN 03 |    |     |    |    |
       ----------------------
VPN 04 |    |     |    |    |
       ----------------------
VPN 05 |    |     |    |    |
       ----------------------
VPN 06 |    |a[0] |a[1]|a[2]|
       ----------------------
VPN 07 |a[3]|a[4] |a[5]|a[6]|
       ----------------------
VPN 08 |a[7]|a[8] |a[9]|    |
       ----------------------
VPN 09 |    |     |    |    |
       ----------------------
VPN 10 |    |     |    |    |
       ----------------------
VPN 12 |    |     |    |    |
       ----------------------
VPN 13 |    |     |    |    |
       ----------------------
VPN 14 |    |     |    |    |
       ----------------------
VPN 15 |    |     |    |    |
       ----------------------
examin simple virtual address trace and see how a TLB can improve performance!!
assume:
I)  we have 10 4-bytes integers, starting at virtual address 100.
II) Assume further that we have a small 8-bit virtual address space, with 16-byte pages,
    VPN will break down to 4-bit(16-Virtual pages) and 4-bit offset(16 bit on each page)

III) VPN 06, offset 04 array's first entry and only three 4-byte integers fit onto that page,(a[0]....a[2])
     VPN 07, next four entries (a[3]....a[6]),
     VPN 08, last final three entries of 10-entry array(a[7].....a[9])
;--------------------------------------------------------------------------------------------------------------------
Now let‚Äôs consider a simple loop that accesses each array element,
something that would look like this in C:
int sum = 0;
for (i = 0; i < 10; i++) {
sum += a[i];
}
will pretend that the only memory accesses the loop generates are to the array
(ignoring the variables i and sum, as well as the instructions themselves).
;--------------------------------------------------------------------------------------------------------------------

I)first array element (a[0]) is accessed, the CPU will see a load to virtual address 100. 
  The hardware extracts the VPN from this (VPN=06), and uses that to check
  the TLB for a valid translation. Assuming this is the first time the program
  accesses the array, the result will be a TLB miss.

II)the next element a[1], some good news here: TLB hit!, second element packed next to the first with the same page.
   we previously accessing the first element, translation already updated to the TLB after first miss.
   a[2] encounters similar success, lives on the same page as a[0], a[1].

III)a[3], TLB miss! (a[4]....a[6]) will hit in TLB, 
    a[7] another miss, a[8],a[9] another hit.


Let us summarize TLB activity during our ten accesses to the array:

miss, hit, hit, miss, hit, hit, hit, miss, hit, hit.
number of hits divided by the total number of accesses = hit rate =  70%
indeed, we desire hit rates that approach 100%),
TLB performance gains benefit fromspatial locality. only first access to page yield TLB miss.


Also note the role that page size plays in this example. 
If the page size had simply been twice as big (32 bytes, not 16), the array access would suffer even fewer misses. 
As typical page sizes are more like 4KB, these types of dense, array-based accesses achieve excellent TLB performance,
encountering only a single miss per page of accesses.


accesses the array again, we‚Äôd likely see an even better result, assuming that we have a big enough TLB to cache the needed
translations: hit, hit, hit, hit, hit, hit, hit, hit, hit, hit. 
In this case, the TLB hit rate would be high becauce of temporal locality ((quick re-referencing of memory in time)) 

;--------------------------------------------------------------------------------------------------------------------------------
With spatial locality, the idea is that if a programaccesses memory at address x, it will
likely soon access memory near x.

With temporal locality, the idea is that an instruction or data item that has been recently accessed
will likely be re-accessed soon in the future.

by keeping copies ofmemory in small, fast on-chip memory. 
Instead of having to go to a (slow) memory to satisfy a request, the processor can first check if a nearby copy exists in a cache; 
if it does, the processor can access it quickly (i.e., in a few cycles) and avoid spending the costly time it takes to access memory (many  nano seconds).

If you want a fast cache, it has to be small,  Any large cache by definition is slow, and thus defeats the purpose.
;--------------------------------------------------------------------------------------------------------------------------------
19.3 Who Handles The TLB Miss?
 the hardware, or the software (OS).

hardware ( ((CISC)) ,complex-instruction set computers) no trust in OS people, so he handle it entirely.
hardware must know where the page-tables are located and that by base register.
hardware walk to-> page-table extract -> correct page-table entre and extract-> the desired translation.
                ->update the TLB with the translation,-> and retry the instruction.

hardware-managed TLBs is the Intel x86 architecture, which uses a fixed multi-level page table,
the current page table is pointed to by the CR3 register [I09].

both RISC or reduced-instruction set computers) have what is known as a software-managed TLB
On a TLB miss, I) the hardware simply raises an exception,II) pauses the current instruction stream, 
III) raises the privilege level to kernel mode, IV)and jumps to a trap handler.

When run, the code will I)lookup the translation in the page table, use special
‚Äúprivileged‚Äù instructions to II)update the TLB, and III)return fromthe trap;
at this point, IV)the hardware retries the instruction (resulting in a TLB hit).

a little different than the return-from-trap we saw before when servicing a system call

##in formar case:
here, when returning from a TLB miss-handling trap, the hardware must resume execution at the instruction that caused the trap.
depending on how a trap or exception was caused, the hardware must save a different
PC when trapping into the OS, in order to resume properlywhen the time to do so arrives.

##in the latter case:
others, the return-from trap should resume execution at the instruction after instruction cause  the trap into the OS.


Second,when running the TLBmiss-handling code, the OS needs to be
extra careful not to cause an infinite chain of TLB misses to occur. Many
solutions exist; for example, you could keep TLB miss handlers in physical
memory (where they are unmapped and not subject to address translation),
or reserve some entries in the TLB for permanently-valid translations
and use some of those permanent translation slots for the handler
code itself; these wired translations always hit in the TLB

flexibility: any data structute to implement page table, without necessitating hardware change.
simplicitys: the hardware doesn‚Äôt have to do much on a miss; it raises an exception, and the OS TLBmiss handler does the rest.
;--------------------------------------------------------------------------------------------------------------------------------
19.4 TLB Contents: What‚Äôs In There?

TLB might have 32, 64, or 128 entries and be what is called fully associative.
any given translation can be anywhere in the TLB, hardware will search the entire TLB in parallel to find desire translation.
			VPN | PEN | otherbits

In a page table, when a page-table entry (PTE) is marked invalid, it means that the page has not been allocated by
the process, and should not be accessed by a correctly-working program. ended to trap to the OS, then killing process.
(Invalid page is accessed)

More interesting are the ‚Äúother bits‚Äù. For example, the TLB commonly has a valid bit, 
which says whether the entry has a valid translation or not.
When a system boots, for example, a common initial state for each TLB entry is to be set to invalid,
because no address translations are yet cached there.

valid bit is quite usefulwhen performing a context switch too, 
By setting all TLB entries to invalid, the system can ensure that the about-to-be-run process does not accidentally
use a virtual-to-physical translation from a previous process.

protection bits, which determine how a page can be accessed (as in the page table).
For example, code pages might be marked read and execute, whereas heap pages might be marked read and write.

address-space identifier, dirty bit,

19.5 TLB Issue: Context Switches
TLB contains virtual-to-physical translation that are only vaild for currently running process;
these translation are not meaningful for other processes.

in context switch hardware or OS(or both), must be carefull that the about-to-run process doesn't accidentally use translation
from previously run process.
 
  VPN     PFN    vaild  prot
   10     100      1     rwx
   --     ---      -     ---
   10     170      1     rwx

process p1 10th virtual page is mapped to physical frame 100, TLB might caching translation that valid for it.
process p2 10th vurtual page is mapped to physical frame 170, TLB might caching translation that valid for it.

but the hardware can‚Äôt distinguish which entry is meant for which process.
Thus, we need to do some more work in order for the TLB to correctly and efficiently support virtualization across multiple processes.
CURSE:the last process are not meaningful to the about-to-be-run process, what OS,hardware do?

flush operation is simply set all vaild bits to 0, essentially clearing content of TLB.
but there is a cost; each time a process runs, it must incur TLB misses. if the OS switches between processes frequently, cost may be high.

hardware enable sharing of the TLB across context switches.
another solution In particular, some hardware systems provide an address space identifier (ASID) field in the TLB.
ASID like PIC process identifier 8-bit for ASID and 32 for PIC.

  VPN     PFN    vaild  prot
   10     101      1     rwx
   --     ---      -     ---
   50     101      1     rwx
add ASIDs, it is clear processes can readily share the TLB: only the ASID field is needed to differentiate otherwise identical translations

Of course, the hardware also needs to know which process is currently running in order to perform translations, and
thus the OS must, on a context switch, set some privileged register to the ASID of the current process

Sharing of code pages (in binaries, or shared libraries) is useful as it reduces the number of physical pages in use, thus reducing memory overheads.

19.6 Issue: Replacement Policy
  LRU,ramdom policy.
19.7 A Real TLB Entry

A Real TLB Entry
-------------------------------------------------------------------------------------------    
Flag                       Content
--------------------------------------------------------------------------------------------
19-bit VPN       The rest reserved for the kernel.    
-------------------------------------------------------------------------------------------    
24-bit PFN       Systems can support with up to 64GB of main memory( 224‚àó4ùêæùêµpages ).  
-------------------------------------------------------------------------------------------         
Global bit(G)    Used for pages that are globally-shared among processes.	
-------------------------------------------------------------------------------------------    	   
ASID             OS can use to distinguish between address spaces. 	
-------------------------------------------------------------------------------------------    		   
Coherence bit(C) determine how a page is cached by the hardware.
-------------------------------------------------------------------------------------------    		           
Dirty bit(D)     marking when the page has been written.	
-------------------------------------------------------------------------------------------    			   
Valid bit(V)     tells the hardware if there is a valid translation present in the entry.  
--------------------------------------------------------------------------------------------
;--------------------------------------------------------------------------------------------------------------------------------