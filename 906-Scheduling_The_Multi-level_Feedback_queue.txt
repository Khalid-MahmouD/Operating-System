the most well-known approaches to scheduling known as the Multi-level-feedback queue (MLFQ);

the fundamental problem MLFQ tries to address is two fold:
I)Optimize turnaround time, which done by shortest job first, 
  but OS doesn't know how long a job will run for, 
  exactly the knowledge that  algorithms like SJF or STCF require.
II)would make system feel responsive to interactive users(e.g..sitting and staring at screen waiting for a process to finish)
   and thus minimize response time; RR reduce response time but terrible for turnaround time.

#how we can build a scheduler to achieve these goals ? how scheduler lean characteristics of the job running, thus make a better scheduling decisions?
#how he could minimizes response time for interactive jobs while also minimizing turnaround time, without a priori knowledge of joblength?


LEARN FROM HISTORY (MLFQ)!!learn from past and predict the future.

----------------------------------------------------------------------------------------------------------------------------------------------------------
8.1 MLFQ: Basic Rules:
 having a number of distinct queues, each assigned to different prioity level, 
 At any given time: job ready to run is on a single queue, 
 MLFQ uses priorities to decide which job should run at a given time: job with higher priorities(higher queue) is chosen to run.
same priority, thus more than one job may be on a given queue.

instade given fixed priority, MLFQ varies the priority of a job based on observed behavior !! 
for example: a job repeatedly given up CPU waiting for Input from Keyboard, MLFQ will keep its priority high, (interactive process might behave).
if a job use CPU intensively for long periods of time, MLFQ reduse its priority .

#MLFQ will try to learn about processes as they run, and thus use the history of the job to predict its future behavior.

first two basics rules for MLFQ:
 .Rule 1: if priority(A) > priority(B), A runs (B doesn't).
 .Rule 2: if priority(A) = priority(B), A & B run in RR.
    Round Robin !! time slicer
4 jobs A&B highest priorty, C middle, D lowest: scheduler will alternate time slices between A and B. poor C and D would never even Run.
we have to understand :How we Can change priority over time? 

----------------------------------------------------------------------------------------------------------------------------------------------------------
8.2 Attempt #1: How to Change Priority 
out workload is a mix of interactive jobs that are shor-running, and some longer-running need a lot of CPU time no matter the response time.
priority adjustment algorithm :
 .Rule 3: when job enter  system, it placed at the highest priority(top most Queue).
 .Rule 4a: if a jobe uses up an entire time slice while running, its priority reduced,(moved down one queue).
 .Rule 4b: If a job gives up the CPU before the time slice is up,it stays at the same priority level.

##A Single Long-Running Job:
	3 queues first at Q2 running for 10ms the scheduler reduce job's priority by one, the Q1 running for another 10 ms(time slice),
        it reduces to the lowest priority queue Q0 and it remain there. 

##Along Came A Short Job
MLFQ tries to approximate SJF        
        two jobs B is short-running interactive job,came at 100, 
        A long-running CPU intensive job, Placed at Q0, when B came it inserten in Q2 reduced after time slice up, and then finished.

because it doesn't know wheather a job will be a short job or a long-running job, it assume it a short job, given a higher priority, if it is, it runs quickly and finished like B, if it is not , it reduced down the queues proveing that is a long-running process.

In this manner, MLFQ approximates SJF. 

##What About I/O?
according to 4b Rule: having job given up CPU before time slice up, it still in the same priotity.


##ProblemsWith Our Current MLFQ
	he seems to do fairly goob job, sharing the CPU fairly between along-running jobs, and letting short or I/O-intensive interactive jobs run quickly.
     
first,starvation: too many interactive jobs(which run first) consume all CPU time, and long-running job won't receve any CPU time(they starve).

seconde,smart user could rewtite program to game the scheduler.gaming means trick scheduler into giving you more than your fair share of the resource.
 befor time slice is over, issue an I/O operation thus given up CPU still in the same priority , gain higher percentage of CPU time,monopolize the CPU.
After running 99% of a time slice, issue an I/O operation.

finally program may change its behavior over time;
CPU bound process I/O bound process

----------------------------------------------------------------------------------------------------------------------------------------------------------
8.3 Attempt #2: The Priority Boost

change rules to avoid starvation,The simple idea here is to periodically boost the priority, simple way throw them all at the the topmost queue
 .Rule 5: after some time period S, move all the jobs in the system to the topmost queue.
Our new rule solves two problems at once:
1)processes are guaranteed no to starve: a job will share CPU with other high-priorit in RR fashion.
2)if a CPU-bond job bacome interavtive it will treated properly(short-running job).

example: a long-running job when competing for the CPU with two short-running interactive jobs.
left: long-running jobs gets starved once the two short jobs arrived.(they consume all CPU Time)
right:time priority boost every 50 ms, push them on the topmost queue, we at least guarantee that the long-running job will make some progress,
 thus getting to run periodically(RR).
voo-doo constants
----------------------------------------------------------------------------------------------------------------------------------------------------------
8.4 Attempt #3: Better Accounting 

how to prevent gaming of our scheduler? 
the culprit, as we might guess are Rules4a,4b. retain its priority by given up CPU before the time slice expires.so what we do ?
simple idead is doing better accounting of CPU time at each level of the MLFQ.

instade forgetting how much of a time slice a process used at a given level, the scheduler should keep track;
once process has used its allotment; it is demoted to the next priority queue.
wheather it uses the time slice in one long burst ormany small ones does notmatter.

 .Rule 4: once a job uses up its time allotment at a given level(regardless of how many times it has given up CPU), its priority is
          reduced (i.e, it moves down one queue).

example: without proctection(gaming behave) befor time slice expired a process can issue I/O, thus domainate CPU.
	   with protection(anti-gaming) regardless of the  I/O behavior of the process, it slowly moves down the queues, 
           and thus can not gain a unfair share of cpu.

----------------------------------------------------------------------------------------------------------------------------------------------------------
8.5 Tuning MLFQ And Other Issues 

how parameterize such a scheduler. for example, how many queues ? how big should time slice be per queue? how often should priority boosted,
to avoid starvation, and account for change in behavior?

most MLFQ variants allow for varying time-slice length across different queues. 
the high-priority queues are usually given a short time slice; comprised of interactive jobs; alternating between them makes sense;10ms;
lower-priority queues, in constract contain long-running jobs; longer time slice work well; 100 ms.

example :which two long-running jobs run for 10 ms at the highest queue, 20 in the middle, and 40 at the lowest. 

OUSTERHOUT’S LAW

The SolarisMLFQimplementation Time-Sharing scheduling or TS.
is particularly easy to configure; provides tables that determine  how the priority of a process is altered throughout its lifetime,
how long each time slice is, and how often to boost the priority ofa job [AD00]
administrator can muck with this table in order to make scheduler behave in different ways
Default values for the table are:
60 queues, 
with slowly increasing time-slice lengths from20 milliseconds(highest priority) 
to a few hundred milliseconds (lowest),
and priorities boosted around every 1 second or so.

adjust priorities using mathematical formulae. don’t use a table or the exact rules described above :DD

basing it on how much CPU
the process has used [LM+89]; in addition, usage is decayed over time,
providing the desired priority boost in a differentmanner than described
herein.